#!/usr/bin/env ruby
# frozen_string_literal: true

require 'bundler/setup'
require_relative '../lib/thatsmybis_scraper'

def main
  puts "That's My BIS Full Scraper".blue.bold
  puts "This will scrape the roster page and all character wishlists".yellow
  
  # Initialize the single WebDriver instance
  driver_manager = ThatsMyBisScraper::WebDriverManager.instance
  shared_driver = driver_manager.driver
  
  begin
    # Initialize components with shared driver
    scraper = ThatsMyBisScraper::Scraper.new(driver: shared_driver)
    retriever = ThatsMyBisScraper::RosterRetriever.new(nil, scraper: scraper)
    character_scraper = ThatsMyBisScraper::CharacterScraper.new(scraper)
    
    puts "\nStep 1: Collecting profile links from roster page...".blue
    profile_links = retriever.collect_profile_links
    
    if profile_links.empty?
      puts "No profile links found!".red
      exit 1
    end
    
    puts "Found #{profile_links.length} character profiles to scrape".green
    
    # Ask user if they want to proceed
    puts "\nThis will scrape #{profile_links.length} character pages.".yellow
    puts "Do you want to continue? (y/n): ".cyan
    response = gets.chomp.downcase
    
    unless response == 'y' || response == 'yes'
      puts "Scraping cancelled by user.".yellow
      exit 0
    end
    
    puts "\nStep 2: Scraping individual character pages...".blue
    puts "Using SINGLE browser session (single authentication required)".green
    
    character_data = []
    profile_links.each_with_index do |profile_link, index|
      puts "\n[#{index + 1}/#{profile_links.length}] Scraping: #{profile_link[:player_name]}".cyan
      
      begin
        char_data = character_scraper.scrape_character_page(profile_link[:url], use_persistent: true)
        character_data << char_data
        
        # Add a small delay between requests to be respectful
        sleep(1)
        
      rescue => e
        puts "Error scraping #{profile_link[:player_name]}: #{e.message}".red
        # Continue with next character instead of failing completely
        next
      end
    end
    
    puts "\nCompleted scraping #{character_data.length} characters".green
    
    puts "\nStep 3: Saving data...".blue
    output_file = save_character_data_to_file(character_data, retriever.base_url)
    
    # Print summary
    puts "\n" + "="*60
    puts "SCRAPING COMPLETE".green.bold
    puts "="*60
    puts "Characters scraped: #{character_data.length}".green
    puts "Output file: #{output_file}".green
    
    # Show some sample data
    if character_data.any?
      sample_char = character_data.first
      puts "\nSample character data:".yellow
      puts "  Name: #{sample_char[:name]}"
      puts "  Class: #{sample_char[:class]}"
      puts "  Level: #{sample_char[:level]}"
      puts "  Wishlists: #{sample_char[:wishlists].length}"
      
      if sample_char[:wishlists].any? && sample_char[:wishlists].first[:items].any?
        sample_item = sample_char[:wishlists].first[:items].first
        puts "  Sample item: #{sample_item[:name]} (#{sample_item[:quality]})"
      end
    end
    
    puts "="*60
    
  rescue ThatsMyBisScraper::Error => e
    puts "Scraper Error: #{e.message}".red
    exit 1
  rescue => e
    puts "Unexpected Error: #{e.message}".red
    puts e.backtrace.first(5).join("\n").red
    exit 1
  ensure
    # Clean up the single WebDriver instance
    driver_manager.cleanup
  end
end

def save_character_data_to_file(character_data, base_url)
  filename = "data/character_data_#{Time.now.strftime('%Y%m%d_%H%M%S')}.json"
  
  FileUtils.mkdir_p('data') unless Dir.exist?('data')
  
  data = {
    base_url: base_url,
    scraped_at: Time.now.iso8601,
    total_characters: character_data.length,
    characters: character_data
  }
  
  File.write(filename, JSON.pretty_generate(data))
  puts "Character data saved to: #{filename}".green
  filename
end

main if __FILE__ == $PROGRAM_NAME
